import numpy as np
from numpy import loadtxt
import xgboost
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier  
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from hyperopt import hp
import pandas as pd

dataset = pd.read_csv(r'C:\Users\Rohit\Desktop\train.csv')
dataset.drop('Loan_ID', axis=1, inplace=True)
dataset.head(5)
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
cat = dataset.select_dtypes(include='O').keys()
cat = list(cat)
for i in cat:
  dataset[i] = le.fit_transform(dataset[i])
for i in dataset.columns:
  dataset[i].fillna(int(dataset[i].mean()), inplace=True)
dataset.to_csv('file2.csv', header=False, index=False)

dataset = loadtxt(r'C:\Users\Rohit\Desktop\file2.csv', delimiter=",")
# split data into X and y
X = dataset[:,0:11]
Y = dataset[:,11]
# CV model
kfold = KFold(n_splits=10)

kfoldn = KFold(n_splits=400)

#xgboost
xgb_model = xgboost.XGBClassifier()
parameters = {'max_depth': [3, 4, 5], 'gamma': [0.5, 1, 1.5, 2, 5], 'reg_alpha' : [40,180,1], 'reg_lambda' :  [0,1], 'colsample_bytree': [0.6, 0.8, 1.0], 'min_child_weight': [1, 5, 10], 'n_estimators': [180], 'seed': [0], 'subsample': [0.6, 0.8, 1.0]}
clf1 = GridSearchCV(xgb_model, parameters, n_jobs=5, cv=kfoldn, scoring='roc_auc', verbose=2, refit=True)
clf1.fit(X, Y)
print(clf1.best_params_)
print(clf1.score(X, Y))

#adaboost
abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())
parameters = {'base_estimator__max_depth':[i for i in range(2,11,2)], 'base_estimator__min_samples_leaf':[5,10], "base_estimator__criterion" : ["gini", "entropy"], "base_estimator__splitter" :   ["best", "random"], 'n_estimators':[10,50,250,1000], 'learning_rate':[0.01,0.1]}
clf2 = GridSearchCV(abc, parameters,verbose=3,scoring='f1',n_jobs=-1)
clf2.fit(X, Y)
print(clf2.best_params_)
print(clf2.score(X, Y))